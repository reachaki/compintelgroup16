{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyOkB8qPZMLdRvz77o7dh98l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reachaki/compintelgroup16/blob/main/compintel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate peft\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n"
      ],
      "metadata": {
        "id": "vWLPwwean0Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n"
      ],
      "metadata": {
        "id": "oVtXzolun3gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('emotion')\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "Hji3JcWcn6U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6).to('cpu')\n"
      ],
      "metadata": {
        "id": "e560Tj3On7Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example['text'],\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "gJuyvew4n8RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "small_val = tokenized_datasets[\"validation\"]  # or .select(range(500)) for even faster evaluation\n"
      ],
      "metadata": {
        "id": "YgflGDo5r4F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {'eval_accuracy': acc}\n"
      ],
      "metadata": {
        "id": "kZ5yahNbrIJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lora_model(lora_rank, lora_alpha, lora_dropout, batch_size=16, learning_rate=2e-5, num_epochs=3):\n",
        "    from transformers import AutoModelForSequenceClassification\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased', num_labels=6).to('cpu')\n",
        "    lora_config = LoraConfig(\n",
        "        r=lora_rank,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=[\"q_lin\", \"v_lin\"],\n",
        "        lora_dropout=lora_dropout,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.SEQ_CLS,\n",
        "        inference_mode=False\n",
        "    )\n",
        "    lora_model = get_peft_model(model, lora_config)\n",
        "    lora_model = lora_model.to('cpu')\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=num_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        logging_dir='./logs',\n",
        "        report_to=[]\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    accuracy = eval_results.get(\"eval_accuracy\", None)\n",
        "    print(f\"Validation accuracy: {accuracy}\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "zc21zqRun9g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lora_model(lora_rank=2, lora_alpha=8, lora_dropout=0.15, num_epochs=3)\n"
      ],
      "metadata": {
        "id": "2xc8V8Tan-7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Define your search space\n",
        "rank_choices = [2, 4, 8, 16]\n",
        "alpha_choices = [8, 16, 32, 64]\n",
        "dropout_choices = [0.05, 0.1, 0.15, 0.2]\n",
        "\n",
        "results = []\n",
        "\n",
        "num_trials = 5  # increase later for real experiments\n",
        "for trial in range(num_trials):\n",
        "    lora_rank = random.choice(rank_choices)\n",
        "    lora_alpha = random.choice(alpha_choices)\n",
        "    lora_dropout = random.choice(dropout_choices)\n",
        "    print(f\"Trial {trial+1}\")\n",
        "    val_acc = train_lora_model(lora_rank, lora_alpha, lora_dropout, num_epochs=1)\n",
        "    results.append({\n",
        "        'trial': trial+1,\n",
        "        'lora_rank': lora_rank,\n",
        "        'lora_alpha': lora_alpha,\n",
        "        'lora_dropout': lora_dropout,\n",
        "        'val_accuracy': val_acc\n",
        "    })\n",
        "\n",
        "# Save results to a DataFrame for easier analysis\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "Z1FWSzgMut1p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}